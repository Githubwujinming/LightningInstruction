# 使用gpus设备训练

这个也很简单，但要注意版本，官方文档给出的是2.0以上的使用方法。使用方法是设置Trainer的accelerator和device 参数。

```python
# 使用k个gpu
# DEFAULT (int) specifies how many GPUs to use per node
Trainer(accelerator="gpu", devices=k)

# Above is equivalent to
Trainer(accelerator="gpu", devices=list(range(k)))

# 使用指定的两块gpu
# Specify which GPUs to use (don't use when running on cluster)
Trainer(accelerator="gpu", devices=[0, 1])


# 和上面一致
# Equivalent using a string
Trainer(accelerator="gpu", devices="0, 1")

# 使用所有的gpu
# To use all available GPUs put -1 or '-1'
# equivalent to list(range(torch.cuda.device_count()))
Trainer(accelerator="gpu", devices=-1)
```